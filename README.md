# Kaggle_comp
Дневник своих действий и сохраненные решения с скором

__День 1__:
----
Прочитан [ресурс](https://habr.com/ru/company/ods/blog/426227/) на habr про правильный подход к
решению задачи:
- Нужно заострить внимание на __валидации__, один из возможных ресурсов для машнного обучения на
  выборке: `KFold` из модуля `sklearn`. Разбть выборку на тренировку и тест, затем обучать и
  тестировать. Но как преобразовать потом значения для целевого признака y?
- Коммитить каждый результат со скором, чтобы безболезненно откатиться к стабильному решению
- Просматривать кернелы, но до них еще 2 недели.
- Создать Pipe со всеми методами, который потом модернизировать

Наблюдения:
- Распределения x_*_0 похоже на равномемрное R[0, 3],
- Распределения x_*_1 похоже на нормальное с большим коэффициентм эксцесса,
- Распределения x_*_2 похоже на синус(???), на каждой из x_1_2, x_2_2, x_3_2, ... скачки через
  определенное число элементов
- Распределение целевого признака похоже на нормальное смещенное распределение

Идеи решения:
- Построить нейронную сеть с скрытыми слоями и после кросс-валидации запустить процесс
  обучения(риск: долгая обучение, переобучение)

Решение:
- огромная ошибка, классификация RandomForest не сработала для этой задачи
- огромная ошибка 2, классификация нормального распределения не сработала

__День 2__:
---

Идеи решения:
- Так как задача регрессии, нужно:
    1. Выделить информативные признаки из всех
    2. Через методы регрессии получить их значение
- После этих действий результатом будет скалярное произведение всех 300 массивов-признаков
  размерности 10000(матрица $A \in \R^{10000\times300}$) на полученный в результате регресии вектор 
  $b\in\R^{300}$. Итогом работы программы будет вектор $y = A\times b; y \in \R^{10000}$

Отправки:
- После применения линейной регрессии к данны ошибка достигла 30.
- Проверка метода корреляций -- ошибка 30, нет сильно значимых признаков, так как максимум
  корелляции был 0.11. Возможно есть незначимые признаки, так как минимум -0.02. В ходе проверки
  __не найдены__ признаки, корреляция которых равна 0.

Написана кросс-валидация с параметром n_splits = 10(эксперементально проверенное
значение/советы из литературы), поэтому выборка train разбита на тренировочную и тестовую.


Реализован ансамбль моделей из модуля sklearn. Для каждой модели подсчитывается точность, потом
лучшие варианты своих моделей(например, для моделей KNN и
RandomForestClassifier). 

- В ходе выполнения обучения выявлено, что для KNN оптимальным
значением соседей будет 23.
- В ходе выполнения обучения для модели RandomForest оптимальным значением n_estimators из
  выборки(50, 100, 200) оказалось 100
- Проведено обучение моделей SGDClassifier, LogisticRegression и показаны значения точностей
  этих моделей:
```bash
KNN 0.053
RandomForest 0.072
Logistic 0.046
SGD 0.038
Gaussian 0.051
Ada 0.065
DecTree 0.04

ensemble 0.046(лучший результат 0.057)
```

Лучше всех сработал алгоритм SGD. После проверки выяснилось, что ошибка на тестовых данных
меньше предыдущих, а также в несколько раз меньше ошибок прошлых посылок. После загрузки в kaggle
результат: 6.68..., лучше методов, связанных с корреляцией и регрессиией.

__Подход к задаче с точки зрения теории вероятностей__

Возможно, стоит рассмотреть нормальное распределение с мат.ожиданием 18.3, $\sigma = 6.87$, так
как график распределения похож на распределение y.

Полученный график гистограммы y очень похож на нормальное распределение с указанными
параметрами.

__День 3__
---
Идеи:
- Так как SVG модель лучше справилась с данными, проверить ее на всей выборке(Результат:
  ошибка уменьшилась, но незначительно -- та же ошибка 6)
- Реализовать правильный подсчет корреляции Пирсона для признаков, проверить явные нули, затем
  проверить значимость корреляций через t-критерий Стьюдента для того, чтобы убрать незначимые
  признаки

Из-за невнимательности рассматривалась модель с худшим параметром точности(который
принимался за ошибку), а самая точная модель в реализации кросс-валидации оказалась
Random-forest, поэтому проверена точность модели при различных параметрах n_estimators:
- n_estimators = 10000 => score = 5.36678 
- n_estimators = 1000 => score = 5.36579
- n_estimators = 500 => score = 5.36579
  
Замечено, что из-за невнимательности иногда оценивались модели классификации, а не регрессии, поэтому
рассмотрены модели регрессии, их оценка приведена ниже:

```bash

```

__Очень интересное наблюдение__
Построен массив корреляций признаков с результатом. Для этого массива посчитан t-критерий Стьюдента
и построен доверительный интервал для 95% -- то есть 95%, что случайная величина(t-критерий
Стьюдента корреляции вектора $y$ с признаком $X_i$)
попадет в искомый интервал. Далее для всех t-критериев проводится отбор:
- если t-критерий корреляции $y$ с признаком $X_i$ не входит в доверительный интервал, то
  маловероятно, что оцененная корреляция:
    - будет входить в 95%-ую вероятность(то есть $y$ практически не зависит от этого признака)
    - вовсе не является корреляцией(то есть скрытые признаки выдали сходство, но сам $y$ от
      конкретного признака не зависит)

По результатом отбора получено число признаков, которые прошли отбор и их индексы:
```bash
32
[59, 62, 71, 83, 101, 107, 110, 119, 140, 142, 152, 162, 168, 174, 189, 190, 198, 205, 211, 222,
226, 228, 232, 240, 241, 246, 252, 259, 261, 276, 291, 298]
```

Лишь $\frac{32}{300}$ признаков оказались значимыми.

__Объединение статистических выводов и лучшего регрессора__

Матрица признаков заменена на матрицу значимых признаков, затем по ней проводится оценка
лучшего регрессора из sklearn:
```bash
KNN 0.038608519097921956
RandomForest 0.04170718524912087
Logistic 0.069
SGD -9.574491199245156e+22
Gaussian 0.052
Ada 0.020337533027445565
DecTree 0.036
```

Результатом ансамбля лучших моделей оказался результат: -0.2347772420088041, поэтому используем
для тестирования модель LogisticRegression для тех 32 признаков, которые показались
значимыми. Score = 5.96720.

Если проверить данный алгоритм на модели RandomForest(n_estimators = 1000) для 32-ух данных, то
получится результат 5.43165, который отличается от лучшего на текущий момент такого же
регрессора, но для 300 признаков с score = 5.36579 не очень значительно. То есть сокращение
выборки в 10 раз выявило значимые результаты.



