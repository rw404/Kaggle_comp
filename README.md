# Kaggle_comp
Дневник своих действий и сохраненные решения с скором

__День 1__:
----
Прочитан [ресурс](https://habr.com/ru/company/ods/blog/426227/) на habr про правильный подход к
решению задачи:
- Нужно заострить внимание на __валидации__, один из возможных ресурсов для машнного обучения на
  выборке: `KFold` из модуля `sklearn`. Разбть выборку на тренировку и тест, затем обучать и
  тестировать. Но как преобразовать потом значения для целевого признака y?
- Коммитить каждый результат со скором, чтобы безболезненно откатиться к стабильному решению
- Просматривать кернелы, но до них еще 2 недели.
- Создать Pipe со всеми методами, который потом модернизировать

Наблюдения:
- Распределения x_*_0 похоже на равномемрное R[0, 3],
- Распределения x_*_1 похоже на нормальное с большим коэффициентм эксцесса,
- Распределения x_*_2 похоже на синус(???), на каждой из x_1_2, x_2_2, x_3_2, ... скачки через
  определенное число элементов
- Распределение целевого признака похоже на нормальное смещенное распределение

Идеи решения:
- Построить нейронную сеть с скрытыми слоями и после кросс-валидации запустить процесс
  обучения(риск: долгая обучение, переобучение)

Решение:
- огромная ошибка, классификация RandomForest не сработала для этой задачи
- огромная ошибка 2, классификация нормального распределения не сработала

