{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных в ноутбук"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Kaggle/xxx_test.csv\n",
      "../../Kaggle/xxx_train.csv\n",
      "../../Kaggle/xxx_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../../Kaggle'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "plt.style.use('seaborn-dark')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # отключение варнингов\n",
    "pd.set_option('display.max_columns', None) # pd.options.display.max_columns = None \n",
    "# pd.set_option('display.max_rows', None) # не прятать столбцы при выводе дата-фреймов\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "plt.rc('font', size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 301) (50000, 300)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../../Kaggle/xxx_train.csv')\n",
    "test = pd.read_csv('../../Kaggle/xxx_test.csv')\n",
    "# размеры данных\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_0_0</th>\n",
       "      <th>X_0_1</th>\n",
       "      <th>X_0_2</th>\n",
       "      <th>X_1_0</th>\n",
       "      <th>X_1_1</th>\n",
       "      <th>X_1_2</th>\n",
       "      <th>X_2_0</th>\n",
       "      <th>X_2_1</th>\n",
       "      <th>X_2_2</th>\n",
       "      <th>X_3_0</th>\n",
       "      <th>X_3_1</th>\n",
       "      <th>X_3_2</th>\n",
       "      <th>X_4_0</th>\n",
       "      <th>X_4_1</th>\n",
       "      <th>X_4_2</th>\n",
       "      <th>X_5_0</th>\n",
       "      <th>X_5_1</th>\n",
       "      <th>X_5_2</th>\n",
       "      <th>X_6_0</th>\n",
       "      <th>X_6_1</th>\n",
       "      <th>X_6_2</th>\n",
       "      <th>X_7_0</th>\n",
       "      <th>X_7_1</th>\n",
       "      <th>X_7_2</th>\n",
       "      <th>X_8_0</th>\n",
       "      <th>X_8_1</th>\n",
       "      <th>X_8_2</th>\n",
       "      <th>X_9_0</th>\n",
       "      <th>X_9_1</th>\n",
       "      <th>X_9_2</th>\n",
       "      <th>X_10_0</th>\n",
       "      <th>X_10_1</th>\n",
       "      <th>X_10_2</th>\n",
       "      <th>X_11_0</th>\n",
       "      <th>X_11_1</th>\n",
       "      <th>X_11_2</th>\n",
       "      <th>X_12_0</th>\n",
       "      <th>X_12_1</th>\n",
       "      <th>X_12_2</th>\n",
       "      <th>X_13_0</th>\n",
       "      <th>X_13_1</th>\n",
       "      <th>X_13_2</th>\n",
       "      <th>X_14_0</th>\n",
       "      <th>X_14_1</th>\n",
       "      <th>X_14_2</th>\n",
       "      <th>X_15_0</th>\n",
       "      <th>X_15_1</th>\n",
       "      <th>X_15_2</th>\n",
       "      <th>X_16_0</th>\n",
       "      <th>X_16_1</th>\n",
       "      <th>X_16_2</th>\n",
       "      <th>X_17_0</th>\n",
       "      <th>X_17_1</th>\n",
       "      <th>X_17_2</th>\n",
       "      <th>X_18_0</th>\n",
       "      <th>X_18_1</th>\n",
       "      <th>X_18_2</th>\n",
       "      <th>X_19_0</th>\n",
       "      <th>X_19_1</th>\n",
       "      <th>X_19_2</th>\n",
       "      <th>X_20_0</th>\n",
       "      <th>X_20_1</th>\n",
       "      <th>X_20_2</th>\n",
       "      <th>X_21_0</th>\n",
       "      <th>X_21_1</th>\n",
       "      <th>X_21_2</th>\n",
       "      <th>X_22_0</th>\n",
       "      <th>X_22_1</th>\n",
       "      <th>X_22_2</th>\n",
       "      <th>X_23_0</th>\n",
       "      <th>X_23_1</th>\n",
       "      <th>X_23_2</th>\n",
       "      <th>X_24_0</th>\n",
       "      <th>X_24_1</th>\n",
       "      <th>X_24_2</th>\n",
       "      <th>X_25_0</th>\n",
       "      <th>X_25_1</th>\n",
       "      <th>X_25_2</th>\n",
       "      <th>X_26_0</th>\n",
       "      <th>X_26_1</th>\n",
       "      <th>X_26_2</th>\n",
       "      <th>X_27_0</th>\n",
       "      <th>X_27_1</th>\n",
       "      <th>X_27_2</th>\n",
       "      <th>X_28_0</th>\n",
       "      <th>X_28_1</th>\n",
       "      <th>X_28_2</th>\n",
       "      <th>X_29_0</th>\n",
       "      <th>X_29_1</th>\n",
       "      <th>X_29_2</th>\n",
       "      <th>X_30_0</th>\n",
       "      <th>X_30_1</th>\n",
       "      <th>X_30_2</th>\n",
       "      <th>X_31_0</th>\n",
       "      <th>X_31_1</th>\n",
       "      <th>X_31_2</th>\n",
       "      <th>X_32_0</th>\n",
       "      <th>X_32_1</th>\n",
       "      <th>X_32_2</th>\n",
       "      <th>X_33_0</th>\n",
       "      <th>X_33_1</th>\n",
       "      <th>X_33_2</th>\n",
       "      <th>X_34_0</th>\n",
       "      <th>X_34_1</th>\n",
       "      <th>X_34_2</th>\n",
       "      <th>X_35_0</th>\n",
       "      <th>X_35_1</th>\n",
       "      <th>X_35_2</th>\n",
       "      <th>X_36_0</th>\n",
       "      <th>X_36_1</th>\n",
       "      <th>X_36_2</th>\n",
       "      <th>X_37_0</th>\n",
       "      <th>X_37_1</th>\n",
       "      <th>X_37_2</th>\n",
       "      <th>X_38_0</th>\n",
       "      <th>X_38_1</th>\n",
       "      <th>X_38_2</th>\n",
       "      <th>X_39_0</th>\n",
       "      <th>X_39_1</th>\n",
       "      <th>X_39_2</th>\n",
       "      <th>X_40_0</th>\n",
       "      <th>X_40_1</th>\n",
       "      <th>X_40_2</th>\n",
       "      <th>X_41_0</th>\n",
       "      <th>X_41_1</th>\n",
       "      <th>X_41_2</th>\n",
       "      <th>X_42_0</th>\n",
       "      <th>X_42_1</th>\n",
       "      <th>X_42_2</th>\n",
       "      <th>X_43_0</th>\n",
       "      <th>X_43_1</th>\n",
       "      <th>X_43_2</th>\n",
       "      <th>X_44_0</th>\n",
       "      <th>X_44_1</th>\n",
       "      <th>X_44_2</th>\n",
       "      <th>X_45_0</th>\n",
       "      <th>X_45_1</th>\n",
       "      <th>X_45_2</th>\n",
       "      <th>X_46_0</th>\n",
       "      <th>X_46_1</th>\n",
       "      <th>X_46_2</th>\n",
       "      <th>X_47_0</th>\n",
       "      <th>X_47_1</th>\n",
       "      <th>X_47_2</th>\n",
       "      <th>X_48_0</th>\n",
       "      <th>X_48_1</th>\n",
       "      <th>X_48_2</th>\n",
       "      <th>X_49_0</th>\n",
       "      <th>X_49_1</th>\n",
       "      <th>X_49_2</th>\n",
       "      <th>X_50_0</th>\n",
       "      <th>X_50_1</th>\n",
       "      <th>X_50_2</th>\n",
       "      <th>X_51_0</th>\n",
       "      <th>X_51_1</th>\n",
       "      <th>X_51_2</th>\n",
       "      <th>X_52_0</th>\n",
       "      <th>X_52_1</th>\n",
       "      <th>X_52_2</th>\n",
       "      <th>X_53_0</th>\n",
       "      <th>X_53_1</th>\n",
       "      <th>X_53_2</th>\n",
       "      <th>X_54_0</th>\n",
       "      <th>X_54_1</th>\n",
       "      <th>X_54_2</th>\n",
       "      <th>X_55_0</th>\n",
       "      <th>X_55_1</th>\n",
       "      <th>X_55_2</th>\n",
       "      <th>X_56_0</th>\n",
       "      <th>X_56_1</th>\n",
       "      <th>X_56_2</th>\n",
       "      <th>X_57_0</th>\n",
       "      <th>X_57_1</th>\n",
       "      <th>X_57_2</th>\n",
       "      <th>X_58_0</th>\n",
       "      <th>X_58_1</th>\n",
       "      <th>X_58_2</th>\n",
       "      <th>X_59_0</th>\n",
       "      <th>X_59_1</th>\n",
       "      <th>X_59_2</th>\n",
       "      <th>X_60_0</th>\n",
       "      <th>X_60_1</th>\n",
       "      <th>X_60_2</th>\n",
       "      <th>X_61_0</th>\n",
       "      <th>X_61_1</th>\n",
       "      <th>X_61_2</th>\n",
       "      <th>X_62_0</th>\n",
       "      <th>X_62_1</th>\n",
       "      <th>X_62_2</th>\n",
       "      <th>X_63_0</th>\n",
       "      <th>X_63_1</th>\n",
       "      <th>X_63_2</th>\n",
       "      <th>X_64_0</th>\n",
       "      <th>X_64_1</th>\n",
       "      <th>X_64_2</th>\n",
       "      <th>X_65_0</th>\n",
       "      <th>X_65_1</th>\n",
       "      <th>X_65_2</th>\n",
       "      <th>X_66_0</th>\n",
       "      <th>X_66_1</th>\n",
       "      <th>X_66_2</th>\n",
       "      <th>X_67_0</th>\n",
       "      <th>X_67_1</th>\n",
       "      <th>X_67_2</th>\n",
       "      <th>X_68_0</th>\n",
       "      <th>X_68_1</th>\n",
       "      <th>X_68_2</th>\n",
       "      <th>X_69_0</th>\n",
       "      <th>X_69_1</th>\n",
       "      <th>X_69_2</th>\n",
       "      <th>X_70_0</th>\n",
       "      <th>X_70_1</th>\n",
       "      <th>X_70_2</th>\n",
       "      <th>X_71_0</th>\n",
       "      <th>X_71_1</th>\n",
       "      <th>X_71_2</th>\n",
       "      <th>X_72_0</th>\n",
       "      <th>X_72_1</th>\n",
       "      <th>X_72_2</th>\n",
       "      <th>X_73_0</th>\n",
       "      <th>X_73_1</th>\n",
       "      <th>X_73_2</th>\n",
       "      <th>X_74_0</th>\n",
       "      <th>X_74_1</th>\n",
       "      <th>X_74_2</th>\n",
       "      <th>X_75_0</th>\n",
       "      <th>X_75_1</th>\n",
       "      <th>X_75_2</th>\n",
       "      <th>X_76_0</th>\n",
       "      <th>X_76_1</th>\n",
       "      <th>X_76_2</th>\n",
       "      <th>X_77_0</th>\n",
       "      <th>X_77_1</th>\n",
       "      <th>X_77_2</th>\n",
       "      <th>X_78_0</th>\n",
       "      <th>X_78_1</th>\n",
       "      <th>X_78_2</th>\n",
       "      <th>X_79_0</th>\n",
       "      <th>X_79_1</th>\n",
       "      <th>X_79_2</th>\n",
       "      <th>X_80_0</th>\n",
       "      <th>X_80_1</th>\n",
       "      <th>X_80_2</th>\n",
       "      <th>X_81_0</th>\n",
       "      <th>X_81_1</th>\n",
       "      <th>X_81_2</th>\n",
       "      <th>X_82_0</th>\n",
       "      <th>X_82_1</th>\n",
       "      <th>X_82_2</th>\n",
       "      <th>X_83_0</th>\n",
       "      <th>X_83_1</th>\n",
       "      <th>X_83_2</th>\n",
       "      <th>X_84_0</th>\n",
       "      <th>X_84_1</th>\n",
       "      <th>X_84_2</th>\n",
       "      <th>X_85_0</th>\n",
       "      <th>X_85_1</th>\n",
       "      <th>X_85_2</th>\n",
       "      <th>X_86_0</th>\n",
       "      <th>X_86_1</th>\n",
       "      <th>X_86_2</th>\n",
       "      <th>X_87_0</th>\n",
       "      <th>X_87_1</th>\n",
       "      <th>X_87_2</th>\n",
       "      <th>X_88_0</th>\n",
       "      <th>X_88_1</th>\n",
       "      <th>X_88_2</th>\n",
       "      <th>X_89_0</th>\n",
       "      <th>X_89_1</th>\n",
       "      <th>X_89_2</th>\n",
       "      <th>X_90_0</th>\n",
       "      <th>X_90_1</th>\n",
       "      <th>X_90_2</th>\n",
       "      <th>X_91_0</th>\n",
       "      <th>X_91_1</th>\n",
       "      <th>X_91_2</th>\n",
       "      <th>X_92_0</th>\n",
       "      <th>X_92_1</th>\n",
       "      <th>X_92_2</th>\n",
       "      <th>X_93_0</th>\n",
       "      <th>X_93_1</th>\n",
       "      <th>X_93_2</th>\n",
       "      <th>X_94_0</th>\n",
       "      <th>X_94_1</th>\n",
       "      <th>X_94_2</th>\n",
       "      <th>X_95_0</th>\n",
       "      <th>X_95_1</th>\n",
       "      <th>X_95_2</th>\n",
       "      <th>X_96_0</th>\n",
       "      <th>X_96_1</th>\n",
       "      <th>X_96_2</th>\n",
       "      <th>X_97_0</th>\n",
       "      <th>X_97_1</th>\n",
       "      <th>X_97_2</th>\n",
       "      <th>X_98_0</th>\n",
       "      <th>X_98_1</th>\n",
       "      <th>X_98_2</th>\n",
       "      <th>X_99_0</th>\n",
       "      <th>X_99_1</th>\n",
       "      <th>X_99_2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.81</td>\n",
       "      <td>3.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.72</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.86</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>3.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.89</td>\n",
       "      <td>3.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.82</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.49</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.66</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.71</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X_0_0  X_0_1  X_0_2  X_1_0  X_1_1  X_1_2  X_2_0  X_2_1  X_2_2  X_3_0  \\\n",
       "3313    0.0    6.0  -1.00    0.0    1.0  -1.00    3.0   65.0   1.10    2.0   \n",
       "2214    1.0   81.0   0.00    1.0   69.0   1.00    2.0   -1.0   1.92    3.0   \n",
       "6274    3.0   13.0   2.98    2.0   -1.0   2.67    0.0    4.0  -1.00    0.0   \n",
       "6017    3.0   47.0   1.13    1.0   68.0   0.00    0.0    3.0  -1.00    2.0   \n",
       "2357    1.0   25.0   1.00    0.0    5.0  -1.00    3.0   13.0   1.31    2.0   \n",
       "\n",
       "      X_3_1  X_3_2  X_4_0  X_4_1  X_4_2  X_5_0  X_5_1  X_5_2  X_6_0  X_6_1  \\\n",
       "3313   -1.0   0.27    2.0   -1.0   2.81    3.0   69.0   2.66    1.0    0.0   \n",
       "2214   35.0   2.21    1.0   65.0   1.00    1.0   75.0   2.00    0.0    2.0   \n",
       "6274    6.0  -1.00    3.0   39.0   2.89    3.0   47.0   1.96    1.0   52.0   \n",
       "6017   -1.0   0.28    3.0   36.0   0.42    3.0   11.0   1.44    1.0   28.0   \n",
       "2357   -1.0   0.99    3.0   49.0   0.46    0.0    4.0  -1.00    3.0   20.0   \n",
       "\n",
       "      X_6_2  X_7_0  X_7_1  X_7_2  X_8_0  X_8_1  X_8_2  X_9_0  X_9_1  X_9_2  \\\n",
       "3313   1.00    2.0   -1.0   2.36    1.0   83.0   2.00    2.0   -1.0   2.00   \n",
       "2214  -1.00    3.0   13.0   1.40    1.0   45.0   0.00    2.0   -1.0   1.38   \n",
       "6274   2.00    1.0   58.0   3.00    2.0   -1.0   0.09    0.0    6.0  -1.00   \n",
       "6017   0.00    1.0   15.0   1.00    0.0    3.0  -1.00    0.0    5.0  -1.00   \n",
       "2357   2.59    0.0    4.0  -1.00    3.0   73.0   2.75    0.0    3.0  -1.00   \n",
       "\n",
       "      X_10_0  X_10_1  X_10_2  X_11_0  X_11_1  X_11_2  X_12_0  X_12_1  X_12_2  \\\n",
       "3313     1.0    91.0    2.00     1.0    23.0    2.00     1.0     7.0    0.00   \n",
       "2214     0.0     2.0   -1.00     2.0    -1.0    1.00     3.0    89.0    1.43   \n",
       "6274     2.0    -1.0    1.71     0.0     3.0   -1.00     0.0     4.0   -1.00   \n",
       "6017     0.0     3.0   -1.00     3.0    11.0    1.73     0.0     4.0   -1.00   \n",
       "2357     1.0    13.0    3.00     2.0    -1.0    1.25     0.0     6.0   -1.00   \n",
       "\n",
       "      X_13_0  X_13_1  X_13_2  X_14_0  X_14_1  X_14_2  X_15_0  X_15_1  X_15_2  \\\n",
       "3313     0.0     4.0   -1.00     1.0    91.0     0.0     1.0    27.0    0.00   \n",
       "2214     0.0     1.0   -1.00     0.0     1.0    -1.0     0.0     3.0   -1.00   \n",
       "6274     3.0    78.0    2.58     0.0     4.0    -1.0     3.0    82.0    2.17   \n",
       "6017     2.0    -1.0    2.27     0.0     2.0    -1.0     1.0    70.0    2.00   \n",
       "2357     1.0    70.0    2.00     1.0    75.0     0.0     1.0    35.0    3.00   \n",
       "\n",
       "      X_16_0  X_16_1  X_16_2  X_17_0  X_17_1  X_17_2  X_18_0  X_18_1  X_18_2  \\\n",
       "3313     2.0    -1.0    0.98     2.0    -1.0    0.68     3.0    45.0    0.46   \n",
       "2214     2.0    -1.0    2.46     0.0     2.0   -1.00     2.0    -1.0    2.16   \n",
       "6274     3.0    91.0    1.74     3.0    64.0    0.62     1.0     4.0    1.00   \n",
       "6017     2.0    -1.0    2.00     3.0    20.0    1.83     2.0    -1.0    1.45   \n",
       "2357     1.0    83.0    3.00     3.0    78.0    1.99     2.0    -1.0    2.44   \n",
       "\n",
       "      X_19_0  X_19_1  X_19_2  X_20_0  X_20_1  X_20_2  X_21_0  X_21_1  X_21_2  \\\n",
       "3313     2.0    -1.0    2.67     1.0    44.0    1.00     1.0    56.0    2.00   \n",
       "2214     3.0    90.0    1.49     2.0    -1.0    1.73     2.0    -1.0    1.61   \n",
       "6274     1.0     7.0    0.00     0.0     2.0   -1.00     3.0    52.0    1.60   \n",
       "6017     0.0     4.0   -1.00     0.0     6.0   -1.00     3.0    40.0    2.66   \n",
       "2357     2.0    -1.0    1.48     3.0    48.0    2.29     0.0     4.0   -1.00   \n",
       "\n",
       "      X_22_0  X_22_1  X_22_2  X_23_0  X_23_1  X_23_2  X_24_0  X_24_1  X_24_2  \\\n",
       "3313     3.0    39.0    1.28     1.0     9.0    1.00     0.0     4.0   -1.00   \n",
       "2214     1.0    68.0    2.00     3.0    12.0    1.93     0.0     6.0   -1.00   \n",
       "6274     3.0     9.0    2.98     1.0    43.0    0.00     3.0    45.0    0.69   \n",
       "6017     0.0     2.0   -1.00     1.0    28.0    0.00     2.0    -1.0    0.31   \n",
       "2357     3.0     5.0    2.25     0.0     3.0   -1.00     0.0     6.0   -1.00   \n",
       "\n",
       "      X_25_0  X_25_1  X_25_2  X_26_0  X_26_1  X_26_2  X_27_0  X_27_1  X_27_2  \\\n",
       "3313     1.0    78.0    0.00     1.0    73.0    2.00     2.0    -1.0    1.40   \n",
       "2214     3.0    11.0    0.11     2.0    -1.0    2.80     3.0    86.0    0.76   \n",
       "6274     1.0    89.0    1.00     2.0    -1.0    0.52     3.0    58.0    1.95   \n",
       "6017     1.0    70.0    1.00     0.0     1.0   -1.00     2.0    -1.0    1.04   \n",
       "2357     1.0    14.0    0.00     0.0     3.0   -1.00     1.0     3.0    2.00   \n",
       "\n",
       "      X_28_0  X_28_1  X_28_2  X_29_0  X_29_1  X_29_2  X_30_0  X_30_1  X_30_2  \\\n",
       "3313     3.0     6.0    0.59     2.0    -1.0    2.25     1.0    30.0    3.00   \n",
       "2214     3.0    83.0    1.74     3.0    82.0    1.89     2.0    -1.0    2.23   \n",
       "6274     1.0    42.0    3.00     0.0     2.0   -1.00     0.0     2.0   -1.00   \n",
       "6017     3.0    23.0    1.23     0.0     1.0   -1.00     3.0    96.0    1.67   \n",
       "2357     0.0     1.0   -1.00     0.0     6.0   -1.00     0.0     3.0   -1.00   \n",
       "\n",
       "      X_31_0  X_31_1  X_31_2  X_32_0  X_32_1  X_32_2  X_33_0  X_33_1  X_33_2  \\\n",
       "3313     3.0    61.0    1.09     1.0    72.0    0.00     0.0     1.0    -1.0   \n",
       "2214     2.0    -1.0    2.04     1.0    87.0    2.00     0.0     4.0    -1.0   \n",
       "6274     1.0    41.0    2.00     2.0    -1.0    0.24     1.0    73.0     3.0   \n",
       "6017     0.0     6.0   -1.00     0.0     4.0   -1.00     0.0     1.0    -1.0   \n",
       "2357     2.0    -1.0    0.93     2.0    -1.0    2.22     1.0    45.0     2.0   \n",
       "\n",
       "      X_34_0  X_34_1  X_34_2  X_35_0  X_35_1  X_35_2  X_36_0  X_36_1  X_36_2  \\\n",
       "3313     0.0     4.0    -1.0     0.0     3.0    -1.0     2.0    -1.0    1.30   \n",
       "2214     1.0    71.0     3.0     0.0     2.0    -1.0     2.0    -1.0    0.82   \n",
       "6274     1.0    42.0     1.0     0.0     5.0    -1.0     3.0    42.0    2.25   \n",
       "6017     1.0    36.0     0.0     0.0     3.0    -1.0     2.0    -1.0    0.32   \n",
       "2357     0.0     5.0    -1.0     1.0    79.0     3.0     1.0    79.0    0.00   \n",
       "\n",
       "      X_37_0  X_37_1  X_37_2  X_38_0  X_38_1  X_38_2  X_39_0  X_39_1  X_39_2  \\\n",
       "3313     1.0    42.0     1.0     0.0     6.0   -1.00     0.0     5.0   -1.00   \n",
       "2214     0.0     3.0    -1.0     2.0    -1.0    2.74     1.0    55.0    3.00   \n",
       "6274     0.0     5.0    -1.0     2.0    -1.0    1.14     3.0    20.0    1.35   \n",
       "6017     0.0     3.0    -1.0     2.0    -1.0    2.44     3.0    95.0    0.89   \n",
       "2357     0.0     2.0    -1.0     1.0    54.0    3.00     1.0    57.0    2.00   \n",
       "\n",
       "      X_40_0  X_40_1  X_40_2  X_41_0  X_41_1  X_41_2  X_42_0  X_42_1  X_42_2  \\\n",
       "3313     2.0    -1.0    1.02     2.0    -1.0    2.80     0.0     2.0   -1.00   \n",
       "2214     2.0    -1.0    1.56     3.0     6.0    1.60     2.0    -1.0    0.53   \n",
       "6274     2.0    -1.0    0.67     2.0    -1.0    1.93     3.0    79.0    1.75   \n",
       "6017     1.0    48.0    3.00     0.0     2.0   -1.00     3.0    46.0    2.33   \n",
       "2357     3.0    64.0    2.06     0.0     5.0   -1.00     3.0    54.0    2.35   \n",
       "\n",
       "      X_43_0  X_43_1  X_43_2  X_44_0  X_44_1  X_44_2  X_45_0  X_45_1  X_45_2  \\\n",
       "3313     0.0     4.0    -1.0     2.0    -1.0    0.47     2.0    -1.0    2.72   \n",
       "2214     1.0    13.0     0.0     2.0    -1.0    2.29     1.0    71.0    3.00   \n",
       "6274     0.0     1.0    -1.0     0.0     3.0   -1.00     1.0    53.0    3.00   \n",
       "6017     0.0     2.0    -1.0     0.0     5.0   -1.00     3.0    27.0    2.47   \n",
       "2357     1.0    63.0     3.0     2.0    -1.0    1.57     2.0    -1.0    0.57   \n",
       "\n",
       "      X_46_0  X_46_1  X_46_2  X_47_0  X_47_1  X_47_2  X_48_0  X_48_1  X_48_2  \\\n",
       "3313     3.0    27.0    0.32     2.0    -1.0    2.74     2.0    -1.0    1.22   \n",
       "2214     2.0    -1.0    1.68     1.0     8.0    0.00     2.0    -1.0    0.24   \n",
       "6274     2.0    -1.0    2.89     2.0    -1.0    0.74     0.0     6.0   -1.00   \n",
       "6017     1.0    81.0    2.00     3.0    80.0    0.58     3.0    78.0    0.04   \n",
       "2357     0.0     2.0   -1.00     3.0    34.0    0.89     0.0     4.0   -1.00   \n",
       "\n",
       "      X_49_0  X_49_1  X_49_2  X_50_0  X_50_1  X_50_2  X_51_0  X_51_1  X_51_2  \\\n",
       "3313     3.0    61.0    2.01     3.0    88.0    1.25     2.0    -1.0    0.59   \n",
       "2214     0.0     4.0   -1.00     2.0    -1.0    0.52     0.0     3.0   -1.00   \n",
       "6274     0.0     5.0   -1.00     1.0     0.0    1.00     3.0    86.0    2.32   \n",
       "6017     1.0    33.0    2.00     2.0    -1.0    0.19     1.0    77.0    0.00   \n",
       "2357     3.0    27.0    2.66     3.0    35.0    1.53     3.0    43.0    2.72   \n",
       "\n",
       "      X_52_0  X_52_1  X_52_2  X_53_0  X_53_1  X_53_2  X_54_0  X_54_1  X_54_2  \\\n",
       "3313     3.0    17.0    2.80     2.0    -1.0    0.52     3.0    17.0    1.31   \n",
       "2214     3.0    19.0    2.66     1.0     5.0    3.00     0.0     1.0   -1.00   \n",
       "6274     1.0    41.0    2.00     1.0    76.0    0.00     3.0    54.0    2.92   \n",
       "6017     3.0    27.0    0.79     0.0     5.0   -1.00     0.0     5.0   -1.00   \n",
       "2357     2.0    -1.0    0.29     1.0    83.0    1.00     1.0    58.0    0.00   \n",
       "\n",
       "      X_55_0  X_55_1  X_55_2  X_56_0  X_56_1  X_56_2  X_57_0  X_57_1  X_57_2  \\\n",
       "3313     0.0     3.0   -1.00     1.0    74.0    3.00     1.0    16.0    3.00   \n",
       "2214     1.0    81.0    0.00     3.0    49.0    1.72     2.0    -1.0    1.22   \n",
       "6274     1.0    32.0    2.00     3.0    32.0    1.51     0.0     3.0   -1.00   \n",
       "6017     2.0    -1.0    2.23     2.0    -1.0    2.50     0.0     5.0   -1.00   \n",
       "2357     0.0     3.0   -1.00     3.0    76.0    2.40     0.0     1.0   -1.00   \n",
       "\n",
       "      X_58_0  X_58_1  X_58_2  X_59_0  X_59_1  X_59_2  X_60_0  X_60_1  X_60_2  \\\n",
       "3313     1.0    17.0    1.00     1.0    47.0    1.00     2.0    -1.0    2.65   \n",
       "2214     1.0    87.0    3.00     0.0     6.0   -1.00     2.0    -1.0    0.95   \n",
       "6274     3.0    47.0    2.21     2.0    -1.0    1.63     0.0     4.0   -1.00   \n",
       "6017     2.0    -1.0    1.66     3.0    22.0    1.26     3.0    18.0    0.11   \n",
       "2357     3.0    92.0    2.62     1.0    32.0    2.00     3.0    42.0    0.39   \n",
       "\n",
       "      X_61_0  X_61_1  X_61_2  X_62_0  X_62_1  X_62_2  X_63_0  X_63_1  X_63_2  \\\n",
       "3313     3.0    83.0    1.55     0.0     5.0   -1.00     1.0    93.0    0.00   \n",
       "2214     3.0    70.0    0.80     2.0    -1.0    1.86     2.0    -1.0    2.74   \n",
       "6274     2.0    -1.0    2.82     0.0     5.0   -1.00     0.0     3.0   -1.00   \n",
       "6017     1.0    76.0    1.00     1.0    58.0    0.00     0.0     5.0   -1.00   \n",
       "2357     0.0     5.0   -1.00     0.0     5.0   -1.00     3.0    61.0    1.33   \n",
       "\n",
       "      X_64_0  X_64_1  X_64_2  X_65_0  X_65_1  X_65_2  X_66_0  X_66_1  X_66_2  \\\n",
       "3313     2.0    -1.0    0.60     3.0    15.0    0.08     1.0    46.0    3.00   \n",
       "2214     3.0     6.0    1.79     0.0     4.0   -1.00     3.0    23.0    2.42   \n",
       "6274     3.0    25.0    1.12     1.0    85.0    2.00     3.0     3.0    1.89   \n",
       "6017     3.0    47.0    2.90     3.0    15.0    1.45     3.0    49.0    1.83   \n",
       "2357     0.0     5.0   -1.00     2.0    -1.0    1.13     3.0    62.0    1.10   \n",
       "\n",
       "      X_67_0  X_67_1  X_67_2  X_68_0  X_68_1  X_68_2  X_69_0  X_69_1  X_69_2  \\\n",
       "3313     2.0    -1.0    2.27     2.0    -1.0    0.16     0.0     5.0   -1.00   \n",
       "2214     2.0    -1.0    2.53     0.0     4.0   -1.00     1.0    91.0    1.00   \n",
       "6274     3.0    93.0    0.82     3.0    33.0    2.98     1.0    46.0    3.00   \n",
       "6017     3.0    30.0    0.69     1.0    15.0    1.00     2.0    -1.0    0.58   \n",
       "2357     0.0     3.0   -1.00     2.0    -1.0    1.68     1.0    86.0    3.00   \n",
       "\n",
       "      X_70_0  X_70_1  X_70_2  X_71_0  X_71_1  X_71_2  X_72_0  X_72_1  X_72_2  \\\n",
       "3313     1.0    91.0     2.0     3.0    44.0    1.69     1.0    69.0    3.00   \n",
       "2214     1.0    40.0     3.0     2.0    -1.0    1.16     3.0    25.0    2.17   \n",
       "6274     1.0    21.0     3.0     2.0    -1.0    1.65     1.0    35.0    0.00   \n",
       "6017     0.0     1.0    -1.0     0.0     5.0   -1.00     0.0     4.0   -1.00   \n",
       "2357     0.0     1.0    -1.0     0.0     2.0   -1.00     3.0    93.0    1.70   \n",
       "\n",
       "      X_73_0  X_73_1  X_73_2  X_74_0  X_74_1  X_74_2  X_75_0  X_75_1  X_75_2  \\\n",
       "3313     3.0    23.0    1.86     3.0    61.0    0.67     0.0     6.0   -1.00   \n",
       "2214     1.0    43.0    3.00     0.0     2.0   -1.00     2.0    -1.0    2.00   \n",
       "6274     0.0     2.0   -1.00     0.0     3.0   -1.00     2.0    -1.0    2.41   \n",
       "6017     1.0    65.0    3.00     1.0    55.0    1.00     0.0     6.0   -1.00   \n",
       "2357     1.0    47.0    1.00     0.0     5.0   -1.00     0.0     5.0   -1.00   \n",
       "\n",
       "      X_76_0  X_76_1  X_76_2  X_77_0  X_77_1  X_77_2  X_78_0  X_78_1  X_78_2  \\\n",
       "3313     1.0    25.0    2.00     2.0    -1.0    2.28     1.0    37.0    0.00   \n",
       "2214     0.0     3.0   -1.00     0.0     1.0   -1.00     3.0    89.0    2.17   \n",
       "6274     1.0    34.0    0.00     0.0     1.0   -1.00     1.0    86.0    3.00   \n",
       "6017     0.0     3.0   -1.00     3.0    11.0    2.20     3.0    22.0    0.28   \n",
       "2357     3.0    77.0    0.23     2.0    -1.0    2.36     2.0    -1.0    2.06   \n",
       "\n",
       "      X_79_0  X_79_1  X_79_2  X_80_0  X_80_1  X_80_2  X_81_0  X_81_1  X_81_2  \\\n",
       "3313     1.0    21.0    0.00     2.0    -1.0    1.46     3.0    91.0    1.27   \n",
       "2214     0.0     1.0   -1.00     2.0    -1.0    2.83     1.0    46.0    3.00   \n",
       "6274     3.0     2.0    2.50     3.0    21.0    1.45     3.0    97.0    0.74   \n",
       "6017     2.0    -1.0    0.89     2.0    -1.0    1.54     2.0    -1.0    2.99   \n",
       "2357     1.0    32.0    3.00     2.0    -1.0    1.37     0.0     4.0   -1.00   \n",
       "\n",
       "      X_82_0  X_82_1  X_82_2  X_83_0  X_83_1  X_83_2  X_84_0  X_84_1  X_84_2  \\\n",
       "3313     2.0    -1.0    1.61     0.0     3.0   -1.00     1.0    78.0    0.00   \n",
       "2214     0.0     4.0   -1.00     2.0    -1.0    1.47     1.0    42.0    2.00   \n",
       "6274     2.0    -1.0    2.63     1.0    12.0    3.00     0.0     6.0   -1.00   \n",
       "6017     1.0    30.0    3.00     1.0    94.0    2.00     2.0    -1.0    1.82   \n",
       "2357     1.0    94.0    3.00     3.0    38.0    2.26     3.0     9.0    1.98   \n",
       "\n",
       "      X_85_0  X_85_1  X_85_2  X_86_0  X_86_1  X_86_2  X_87_0  X_87_1  X_87_2  \\\n",
       "3313     3.0    67.0    1.23     3.0    98.0    1.44     1.0    97.0    3.00   \n",
       "2214     2.0    -1.0    0.82     1.0    12.0    3.00     1.0    43.0    3.00   \n",
       "6274     3.0    70.0    0.34     1.0    82.0    0.00     0.0     3.0   -1.00   \n",
       "6017     3.0    94.0    1.95     1.0    79.0    1.00     0.0     1.0   -1.00   \n",
       "2357     0.0     4.0   -1.00     0.0     2.0   -1.00     2.0    -1.0    2.53   \n",
       "\n",
       "      X_88_0  X_88_1  X_88_2  X_89_0  X_89_1  X_89_2  X_90_0  X_90_1  X_90_2  \\\n",
       "3313     3.0    66.0    0.96     1.0    64.0    2.00     0.0     2.0   -1.00   \n",
       "2214     3.0     8.0    0.70     2.0    -1.0    2.35     3.0    57.0    1.77   \n",
       "6274     0.0     1.0   -1.00     0.0     1.0   -1.00     1.0    90.0    3.00   \n",
       "6017     0.0     1.0   -1.00     2.0    -1.0    2.03     0.0     3.0   -1.00   \n",
       "2357     1.0     7.0    2.00     3.0    39.0    0.38     0.0     5.0   -1.00   \n",
       "\n",
       "      X_91_0  X_91_1  X_91_2  X_92_0  X_92_1  X_92_2  X_93_0  X_93_1  X_93_2  \\\n",
       "3313     3.0    64.0    2.00     0.0     6.0   -1.00     3.0    71.0    0.67   \n",
       "2214     2.0    -1.0    0.40     3.0    73.0    1.66     1.0    83.0    2.00   \n",
       "6274     2.0    -1.0    1.58     3.0    53.0    1.22     0.0     1.0   -1.00   \n",
       "6017     2.0    -1.0    2.96     0.0     6.0   -1.00     1.0    75.0    1.00   \n",
       "2357     0.0     2.0   -1.00     0.0     3.0   -1.00     2.0    -1.0    1.71   \n",
       "\n",
       "      X_94_0  X_94_1  X_94_2  X_95_0  X_95_1  X_95_2  X_96_0  X_96_1  X_96_2  \\\n",
       "3313     2.0    -1.0    2.66     0.0     4.0   -1.00     3.0    92.0    1.27   \n",
       "2214     1.0     5.0    2.00     0.0     2.0   -1.00     0.0     2.0   -1.00   \n",
       "6274     2.0    -1.0    2.12     2.0    -1.0    1.05     0.0     5.0   -1.00   \n",
       "6017     2.0    -1.0    1.78     1.0    80.0    0.00     2.0    -1.0    1.13   \n",
       "2357     3.0     7.0    2.46     1.0    35.0    0.00     1.0    65.0    2.00   \n",
       "\n",
       "      X_97_0  X_97_1  X_97_2  X_98_0  X_98_1  X_98_2  X_99_0  X_99_1  X_99_2  \\\n",
       "3313     1.0    94.0    3.00     3.0     2.0    0.57     3.0    20.0    0.90   \n",
       "2214     3.0    84.0    2.16     0.0     4.0   -1.00     1.0    39.0    2.00   \n",
       "6274     0.0     2.0   -1.00     1.0     9.0    0.00     3.0    23.0    0.05   \n",
       "6017     2.0    -1.0    1.52     2.0    -1.0    1.37     2.0    -1.0    1.49   \n",
       "2357     0.0     4.0   -1.00     2.0    -1.0    2.13     0.0     5.0   -1.00   \n",
       "\n",
       "         y  \n",
       "3313  24.0  \n",
       "2214  26.0  \n",
       "6274  18.0  \n",
       "6017  12.0  \n",
       "2357  10.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Целевой вектор y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 0), (10000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train.pop('y') # целевой вектор\n",
    "train.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание матрицы признаком $Matrix \\in \\mathbb{R}^{10000\\times300}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix = np.zeros((10000, 300))\n",
    "\n",
    "for i in range(100):\n",
    "    for j in range(3):\n",
    "        ind = 3*i + j\n",
    "        Matrix[:, ind] = np.array(train.pop('X_'+str(i)+'_'+str(j)))\n",
    "\n",
    "print(Matrix.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание Матрицы тестовой выборки $\\mathbb{R}^{50000\\times300}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 300)\n"
     ]
    }
   ],
   "source": [
    "Tester = np.array(test)\n",
    "print(Tester.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение классификаторов Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование кросс-валидации для оценки моделей на данных(Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in kf.split(Matrix, y):\n",
    "    X_train, X_test = Matrix[train_index], Matrix[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Непредвзятая проверка моделей обучения\n",
    "1. Обучаем модели на разбитых в методе KFold данных\n",
    "2. Выводим точности для каждой\n",
    "3. Из лучших составляем ансамбль\n",
    "4. Проверяем его точность в сравнении с отдельными моделями\n",
    "5. Выбираем лучшую модель\n",
    "6. Обучаем модель на всей выборке\n",
    "7. Предсказываем ответ и отправляем на проверку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV     #Поиск лучших моделей\n",
    "from sklearn.neighbors import KNeighborsRegressor    #K ближайших соседей, определим лучший параметр\n",
    "from sklearn.ensemble import RandomForestRegressor   #Случайный лес. ВАЖНО: ограничить max_depth, иначе ооочень долго\n",
    "from sklearn.linear_model import LogisticRegression  #Логистическая регрессия\n",
    "from sklearn.ensemble import VotingRegressor         #Регрессор голосвания - ансамбль лучших моделей\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 24}\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "params_knn = {'n_neighbors': np.arange(1, 25)}\n",
    "knn_gs = GridSearchCV(knn, params_knn, cv=5)\n",
    "knn_gs.fit(X_train, y_train)\n",
    "\n",
    "#save best model\n",
    "knn_best = knn_gs.best_estimator_\n",
    "print(knn_gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=3, n_estimators=10000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=10000, max_depth= 3)\n",
    "rf.fit(Matrix, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=3, n_estimators=500)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1 = RandomForestRegressor(n_estimators=500, max_depth= 3)\n",
    "rf1.fit(Matrix, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=3, n_estimators=1000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestRegressor(n_estimators=1000, max_depth= 3)\n",
    "rf2.fit(Matrix, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-b99d8e27dc89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparams_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_depth'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrf_gs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrf_gs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#rf_gs.fit(Matrix, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#save best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    387\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                                         indices=indices)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \"\"\"\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1243\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "params_rf = {'n_estimators': [100, 500, 1000, 5000, 10000], 'max_depth' : [3]}\n",
    "rf_gs = GridSearchCV(rf, params_rf, cv=5)\n",
    "rf_gs.fit(X_train, y_train)\n",
    "#rf_gs.fit(Matrix, y)\n",
    "#save best model\n",
    "rf_best = rf_gs.best_estimator_\n",
    "print(rf_gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDRegressor()\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostRegressor()\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tre = tree.DecisionTreeRegressor()\n",
    "tre.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ансамбль моделей -- регрессор голосования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[('knn', knn_best), ('rf', rf_best), ('log', log), ('ada', ada), ('dec', tre), ('gaus', model), ('sgd', sgd)]\n",
    "ensemble = VotingClassifier(estimators, voting='hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Проверка результатов__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.fit(X_train, y_train)\n",
    "ensemble.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Проверка точности предыдущих моделей__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, X_test = X_test, y_test = y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KNN \" + str(accuracy(knn_best)))\n",
    "print(\"RandomForest \" + str(accuracy(rf_best)))\n",
    "print(\"Logistic \" + str(accuracy(log)))\n",
    "print(\"SGD \" + str(accuracy(sgd)))\n",
    "print(\"Gaussian \" + str(accuracy(model)))\n",
    "print(\"Ada \" + str(accuracy(ada)))\n",
    "print(\"DecTree \" + str(accuracy(tre)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результат регрессоров sklearn\n",
    "Лучшей моделью оказался:\n",
    "\n",
    "Точность:\n",
    "\n",
    "Ошибка:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование корреляции Пирсона и t-критерия Стьюдента для выбора значимых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка на нормальность распределения y, то есть $Y \\sim \\mathbb{N}(18.3, 6.87^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 6.87\n",
    "mu = 18.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0a8a02fb80>]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count, bins, ignored = plt.hist(y, 47, density=True)\n",
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
    "        np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "        linewidth=2, color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение корреляции Пирсона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson(a,b):\n",
    "    a_avg, b_avg = np.average(a), np.average(b)\n",
    "    a_stdev, b_stdev = np.std(a), np.std(b)\n",
    "    n = len(a)\n",
    "    denominator = a_stdev * b_stdev * n\n",
    "    numerator = np.sum(np.multiply(a-a_avg, b-b_avg))\n",
    "    p_coef = numerator/denominator\n",
    "    return p_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Корреляции входных признаков с ответом y\n",
    "corrs = np.zeros((300))\n",
    "for i in range(300):\n",
    "    corrs[i] = pearson(Matrix[:,i], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-критерий Стьюдента для оценки значимости корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.zeros_like(corrs)\n",
    "t = corrs/np.sqrt(1-corrs**2) * np.sqrt(300-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получение результирующего вектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tester.dot(mas1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подход к задаче с точки зрения теории вероятностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
    "        np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "        linewidth=2, color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть $y_j(x) = \\frac{1}{10000}\\sum_{i = 1}^{10000}F_X(x[i])$, где $F_X(x)$ - функция распределения величины $X \\sim N(18.3, 6.87^2)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_X(x):\n",
    "    add = erf((x-mu)/np.sqrt(2)*sigma)\n",
    "    return 1/2 * (1+add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Y_Norm(X):\n",
    "    ans = 0\n",
    "    for i in range(len(X)):\n",
    "        ans += F_X(X[i])\n",
    "    ans /= 10000\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_normal = np.zeros((300))\n",
    "for i in range(300):\n",
    "    check_normal[i] = Y_Norm(Matrix[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(check_normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-29.16329088520334\n",
      "[33440.0784986  41421.52724373 41723.76766797 ... 39552.88513586\n",
      " 32645.67032386 30680.36151207]\n",
      "0       19.0\n",
      "1       25.0\n",
      "2       22.0\n",
      "3       22.0\n",
      "4       24.0\n",
      "        ... \n",
      "9995    14.0\n",
      "9996     7.0\n",
      "9997    18.0\n",
      "9998     7.0\n",
      "9999     9.0\n",
      "Name: y, Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "dif = (y - Matrix.dot(mas)).mean()\n",
    "print(dif)\n",
    "x = Matrix.dot(check_normal)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count, bins, ignored = plt.hist(y, 47, density=True)\n",
    "#plt.hist(mas, 47, density=True, color = 'g')\n",
    "#plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
    "#        np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "#        linewidth=2, color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка лучшей модели из sklearn(SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.046968373244672\n",
      "(50000,)\n",
      "16.0\n"
     ]
    }
   ],
   "source": [
    "y_lol = sgd.predict(Matrix)\n",
    "dif = np.sqrt(((y - y_lol)**2).mean())\n",
    "print(dif)\n",
    "y_ans = sgd.predict(tester)\n",
    "print(y_ans.shape)\n",
    "print(y_ans[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Проверка модели на всей тренировочной вборке__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_all = SGDClassifier()\n",
    "sgd_all.fit(Matrix, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.817474016586176\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = sgd_all.predict(Matrix)\n",
    "dif = np.sqrt(((y - y_pred1)**2).mean())\n",
    "print(dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_answ = sgd_all.predict(tester)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Корреляция Пирсона и ее значимость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0255976947107008\n",
      "0.1117076952206865\n",
      "266\n",
      "3\n",
      "[-1.41473956e-02 -7.55642467e-04 -1.15396292e-02 -2.55976947e-02\n",
      " -1.36281331e-02 -1.71708084e-02 -8.60110177e-03 -1.26859204e-02\n",
      "  3.42765711e-03 -6.82905798e-03  3.12696540e-03  4.99891572e-03\n",
      "  1.69692005e-02  1.06018528e-02  1.27991737e-02  6.78863814e-03\n",
      " -2.55843859e-02  7.74365099e-03  1.58592445e-02 -1.31299169e-02\n",
      "  1.29985556e-02  2.05401013e-02  1.21582770e-02  2.16959244e-02\n",
      "  9.61595732e-03 -8.03203262e-03  9.94321183e-04 -1.09175067e-02\n",
      " -3.08086558e-03  6.34043246e-03 -2.15212242e-02 -1.71004574e-02\n",
      "  4.33201132e-03 -1.40469737e-02 -6.83466712e-04 -9.43188630e-03\n",
      "  1.06826576e-02  1.26557755e-03  4.20724653e-02  1.07900049e-02\n",
      " -2.01598624e-02  8.87916581e-03  9.72287825e-03  4.70678237e-03\n",
      "  1.94043612e-02  5.78968639e-03 -1.70051257e-03  7.91559687e-03\n",
      "  9.85460572e-03 -1.90758870e-03  1.79237335e-02  2.07293591e-02\n",
      " -2.43025823e-03  2.37893142e-02 -1.06132185e-02 -4.00496544e-03\n",
      " -7.96010440e-03  1.59527075e-02 -4.01086023e-03  2.60525543e-02\n",
      "  2.03297588e-02  2.99403821e-03  3.12103235e-02  1.37048329e-02\n",
      "  6.39546887e-03  3.45010579e-02 -1.29793972e-02  9.53957485e-03\n",
      "  2.32120663e-02  1.60704918e-02 -4.56144056e-03  2.69895797e-02\n",
      " -2.15150629e-03  1.79693840e-02  2.29828052e-02 -5.65470154e-03\n",
      "  7.56274262e-03  1.83204988e-02  1.01635005e-02  4.49574125e-03\n",
      "  3.76035298e-02  6.88247570e-03  2.43453582e-02  3.20954094e-02\n",
      "  1.43914509e-02  1.24719777e-02  3.40409299e-02  2.52045504e-02\n",
      "  1.47423001e-02  4.96730697e-02  1.28166725e-02  1.25111595e-02\n",
      "  5.04710590e-02  1.18937733e-02  1.19178596e-02  4.19148089e-02\n",
      "  4.64855893e-03  2.74205161e-03  4.33541253e-02 -3.80890756e-06\n",
      "  9.71990454e-03  2.81970829e-02  6.62724633e-03 -1.99238160e-02\n",
      "  3.68337401e-02  2.48195301e-02  6.04717993e-03  2.66297214e-02\n",
      " -3.60941816e-03 -5.48766241e-03  2.66132210e-02  2.44071857e-02\n",
      "  1.87992665e-02  5.44653508e-02  2.39777503e-02  8.36044068e-03\n",
      "  5.50233473e-02  2.61825091e-03 -9.33615720e-03  3.07359379e-02\n",
      " -3.37470090e-03  8.26210917e-03  4.77481588e-02  1.54193192e-02\n",
      "  9.78975306e-03  4.90460037e-02  2.38366370e-02  6.31313888e-03\n",
      "  4.76149959e-02  7.79501393e-03  3.26429320e-03  3.82799910e-02\n",
      "  1.61881644e-02  1.60833071e-02  4.74348998e-02  1.20084316e-02\n",
      "  6.42330952e-03  5.68944624e-02 -5.25048800e-03 -2.31653613e-04\n",
      "  2.62318377e-02  7.15177705e-05  2.73172497e-02  4.37141236e-02\n",
      "  1.91323685e-02  3.41706003e-04  5.14609564e-02  1.08657158e-02\n",
      "  7.27812518e-03  4.21096846e-02  7.21008483e-03 -2.59375816e-03\n",
      "  3.15440323e-02  2.22723194e-02  1.20347230e-02  6.14193279e-02\n",
      " -1.97337844e-05  1.68572204e-02  5.20295664e-02  4.53993854e-03\n",
      "  7.42370829e-03  4.94597522e-02  2.85368640e-02  1.22942551e-02\n",
      "  6.66321652e-02  1.82027157e-02  2.42451643e-02  6.59884041e-02\n",
      "  2.73427596e-02  3.86517805e-03  7.38218024e-02  1.15280052e-02\n",
      "  6.96475204e-03  5.53949638e-02  2.72215750e-02  1.69292304e-02\n",
      "  5.98268398e-02  4.65808691e-03  8.43102677e-03  4.22535650e-02\n",
      "  2.14875192e-02  2.24176318e-02  5.17643330e-02  2.34263094e-02\n",
      "  1.01117370e-02  5.91281501e-02  2.30004683e-02  1.89246894e-02\n",
      "  7.27445933e-02  2.89606975e-02  2.70739845e-02  8.08069815e-02\n",
      "  3.99819640e-02  2.49285438e-02  7.13255651e-02  1.69145593e-02\n",
      "  1.43089640e-02  5.25424601e-02  2.82749561e-02  1.42497597e-02\n",
      "  6.11788881e-02  2.20633698e-02  2.06830858e-02  6.51209597e-02\n",
      "  1.27286859e-02  3.05157274e-02  7.58160288e-02  2.08265804e-02\n",
      "  7.89612113e-03  7.18782725e-02  4.15946283e-02  2.62185212e-02\n",
      "  1.04832443e-01  3.41249040e-02  3.54888642e-02  9.66421594e-02\n",
      "  3.51666449e-02  4.38286782e-02  7.57860756e-02  1.66935588e-02\n",
      "  3.72860819e-02  7.76445211e-02  3.04108947e-02  1.00459751e-02\n",
      "  7.28679671e-02  2.12564775e-02  2.76031449e-02  8.15243511e-02\n",
      "  2.57755350e-02  3.71890669e-02  8.85913781e-02  3.27399004e-02\n",
      "  2.87258108e-02  8.08516208e-02  1.59136547e-02  4.20718717e-02\n",
      "  7.63277942e-02  1.99101084e-02  3.25106231e-02  9.23563254e-02\n",
      "  3.19035614e-02  3.17030527e-02  9.91166765e-02  1.71592188e-02\n",
      "  4.89417806e-02  9.33086443e-02  3.13133247e-02  3.58191136e-02\n",
      "  9.45975737e-02  1.91426542e-02  4.75362761e-02  1.01664730e-01\n",
      "  3.21221049e-02  4.37826001e-02  8.61490115e-02  3.24367519e-02\n",
      "  5.05711119e-02  8.72536853e-02  4.24478256e-02  3.03079542e-02\n",
      "  9.50935496e-02  2.80077076e-02  4.43639163e-02  9.61844309e-02\n",
      "  3.32271673e-02  5.61666048e-02  1.11707695e-01  3.25679476e-02\n",
      "  3.94890180e-02  1.02179787e-01  3.85071018e-02  5.06698817e-02\n",
      "  1.01821729e-01  3.35887688e-02  5.84627598e-02  9.21457312e-02\n",
      "  2.58892795e-02  4.72091889e-02  9.69356660e-02  1.78134435e-02\n",
      "  3.53954615e-02  8.86571128e-02  4.19034807e-02  4.67399652e-02\n",
      "  1.09788083e-01  1.78773261e-02  6.32572161e-02  9.76698435e-02\n",
      "  3.91530652e-02  5.51944558e-02  9.27070698e-02  2.55679676e-02\n",
      "  5.73245736e-02  9.69060962e-02  4.98685509e-02  5.86220629e-02\n",
      "  1.10927484e-01  1.92603624e-02  3.15168534e-02  9.25495372e-02]\n"
     ]
    }
   ],
   "source": [
    "print(corrs.min())\n",
    "print(corrs.max())\n",
    "print(corrs.argmax())\n",
    "print(corrs.argmin())\n",
    "print(corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffac14051f0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count, bins, ignored = plt.hist(y, 47, density=True)\n",
    "plt.hist(Matrix[:, 266], 47, density=True, color = 'g')\n",
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
    "        np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "        linewidth=2, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = LogisticRegression()\n",
    "regr.fit(Matrix, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1409\n",
      "0.2233\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y, regr.predict(Matrix)))\n",
    "y_pred1 = regr.predict(Matrix)\n",
    "dif = (((y - y_pred1)).mean())\n",
    "print(dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "y_answ10000 = rf.predict(Tester)\n",
    "print(y_answ10000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "y_answ1000 = rf1.predict(Tester)\n",
    "print(y_answ1000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "y_answ500 = rf2.predict(Tester)\n",
    "print(y_answ500.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.44246358e-01 -1.30444152e-02 -1.99218150e-01 -4.42029565e-01\n",
      " -2.35279903e-01 -2.96457817e-01 -1.48483530e-01 -2.19010563e-01\n",
      "  5.91708834e-02 -1.17890568e-01  5.39800561e-02  8.62957431e-02\n",
      "  2.92976003e-01  1.83026642e-01  2.20966095e-01  1.17192765e-01\n",
      " -4.41799593e-01  1.33680150e-01  2.73807442e-01 -2.26677047e-01\n",
      "  2.24408819e-01  3.54651945e-01  2.09899917e-01  3.74617903e-01\n",
      "  1.66004836e-01 -1.38658854e-01  1.71646534e-02 -1.88476618e-01\n",
      " -5.31842382e-02  1.09455035e-01 -3.71599996e-01 -2.95242836e-01\n",
      "  7.47828117e-02 -2.42512289e-01 -1.17984675e-02 -1.62826845e-01\n",
      "  1.84421786e-01  2.18472734e-02  7.26927006e-01  1.86275207e-01\n",
      " -3.48083924e-01  1.53284210e-01  1.67850836e-01  8.12525615e-02\n",
      "  3.35034290e-01  9.99471584e-02 -2.93554409e-02  1.36648669e-01\n",
      "  1.70125131e-01 -3.29301465e-02  3.09461326e-01  3.57921129e-01\n",
      " -4.19528856e-02  4.10783489e-01 -1.83222876e-01 -6.91369773e-02\n",
      " -1.37417061e-01  2.75421477e-01 -6.92387396e-02  4.49889522e-01\n",
      "  3.51018594e-01  5.16853447e-02  5.39036316e-01  2.36604318e-01\n",
      "  1.10405168e-01  5.95935384e-01 -2.24078010e-01  1.64686088e-01\n",
      "  4.00810384e-01  2.77455532e-01 -7.87434919e-02  4.66082169e-01\n",
      " -3.71408430e-02  3.10249757e-01  3.96849555e-01 -9.76168441e-02\n",
      "  1.30556913e-01  3.16313933e-01  1.75458284e-01  7.76093111e-02\n",
      "  6.49597007e-01  1.18812766e-01  4.20390643e-01  5.54338260e-01\n",
      "  2.48460693e-01  2.15316464e-01  5.87978330e-01  4.35236268e-01\n",
      "  2.54519216e-01  8.58549987e-01  2.21268245e-01  2.15993004e-01\n",
      "  8.72377388e-01  2.05332885e-01  2.05748768e-01  7.24198221e-01\n",
      "  8.02474361e-02  4.73353278e-02  7.49112580e-01 -6.57519390e-05\n",
      "  1.67799494e-01  4.86950739e-01  1.14406522e-01 -3.44006675e-01\n",
      "  6.36280716e-01  4.28583544e-01  1.04392420e-01  4.59863349e-01\n",
      " -6.23086239e-02 -9.47331673e-02  4.59578206e-01  4.21458904e-01\n",
      "  3.24583016e-01  9.41615408e-01  4.14039187e-01  1.44328627e-01\n",
      "  9.51291385e-01  4.51981734e-02 -1.61174086e-01  5.30835351e-01\n",
      " -5.82567017e-02  1.42630986e-01  8.25202239e-01  2.66210368e-01\n",
      "  1.69005439e-01  8.47685468e-01  4.11601103e-01  1.08983846e-01\n",
      "  8.22895630e-01  1.34566892e-01  5.63507377e-02  6.61299799e-01\n",
      "  2.79487668e-01  2.77676843e-01  8.19776127e-01  2.07312619e-01\n",
      "  1.10885802e-01  9.83744170e-01 -9.06387252e-02 -3.99896149e-03\n",
      "  4.52987608e-01  1.23458814e-03  4.71744893e-01  7.55344824e-01\n",
      "  3.30336354e-01  5.89876053e-03  8.89532467e-01  1.87582410e-01\n",
      "  1.25643248e-01  7.27571224e-01  1.24468597e-01 -4.47753587e-02\n",
      "  5.44805541e-01  3.84575242e-01  2.07766576e-01  1.06226749e+00\n",
      " -3.40657936e-04  2.91042098e-01  8.99387754e-01  7.83722981e-02\n",
      "  1.28156606e-01  8.54853943e-01  4.92823358e-01  2.12247791e-01\n",
      "  1.15281151e+00  3.14279664e-01  4.18659496e-01  1.14162477e+00\n",
      "  4.72185757e-01  6.67238167e-02  1.27784857e+00  1.99017449e-01\n",
      "  1.20233178e-01  9.57735924e-01  4.70091448e-01  2.92285716e-01\n",
      "  1.03462463e+00  8.04119199e-02  1.45547261e-01  7.30061628e-01\n",
      "  3.71017754e-01  3.87085603e-01  8.94790555e-01  4.04511812e-01\n",
      "  1.74564569e-01  1.02249909e+00  3.97154709e-01  3.26749308e-01\n",
      "  1.25910224e+00  5.00148940e-01  4.67540821e-01  1.39952154e+00\n",
      "  6.90748032e-01  4.30467161e-01  1.23441410e+00  2.92032344e-01\n",
      "  2.47036308e-01  9.08278105e-01  4.88296648e-01  2.46013971e-01\n",
      "  1.05809336e+00  3.80965552e-01  3.57121813e-01  1.12655331e+00\n",
      "  2.19748990e-01  5.27028574e-01  1.31256537e+00  3.59600516e-01\n",
      "  1.36312434e-01  1.24402916e+00  7.18656561e-01  4.52757491e-01\n",
      "  1.81971536e+00  5.89430477e-01  6.13018939e-01  1.67614806e+00\n",
      "  6.07446143e-01  7.57328039e-01  1.31204381e+00  2.88215667e-01\n",
      "  6.44105460e-01  1.34441088e+00  5.25216359e-01  1.73429170e-01\n",
      "  1.26124905e+00  3.67026623e-01  4.76685797e-01  1.41202865e+00\n",
      "  4.45102606e-01  6.42427232e-01  1.53536126e+00  5.65481461e-01\n",
      "  4.96089102e-01  1.40029975e+00  2.74747064e-01  7.26916733e-01\n",
      "  1.32147706e+00  3.43769905e-01  5.61517194e-01  1.60116069e+00\n",
      "  5.51021357e-01  5.47554782e-01  1.71948618e+00  2.96257662e-01\n",
      "  8.45879801e-01  1.61781509e+00  5.40817002e-01  6.18730816e-01\n",
      "  1.64036337e+00  3.30514010e-01  8.21532088e-01  1.76414589e+00\n",
      "  5.54799809e-01  7.56530312e-01  1.49271203e+00  5.60239959e-01\n",
      "  8.74111203e-01  1.51199872e+00  7.33424128e-01  5.23436871e-01\n",
      "  1.64904208e+00  4.83677739e-01  7.66594697e-01  1.66813497e+00\n",
      "  5.73906737e-01  9.71118926e-01  1.94051931e+00  5.62508342e-01\n",
      "  6.82218270e-01  1.77317750e+00  6.65229024e-01  8.75822808e-01\n",
      "  1.76689873e+00  5.80159412e-01  1.01095285e+00  1.59747837e+00\n",
      "  4.47068106e-01  8.15866628e-01  1.68128681e+00  3.07556513e-01\n",
      "  6.11403516e-01  1.53650952e+00  7.24002149e-01  8.07739685e-01\n",
      "  1.90676251e+00  3.08659825e-01  1.09418022e+00  1.69414283e+00\n",
      "  6.76405349e-01  9.54258685e-01  1.60729409e+00  4.41515891e-01\n",
      "  9.91205513e-01  1.68076908e+00  8.61937093e-01  1.01371705e+00\n",
      "  1.92679649e+00  3.32547091e-01  5.44335659e-01  1.60453927e+00]\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Rando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка к отпарвке решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка нулевого решения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранить решение\n",
    "pd.DataFrame({'id': np.arange(50000), 'y':y_answ500}).to_csv('solution2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
